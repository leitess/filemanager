"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[585],{3487:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"backend/upload-de-um-arquivo","title":"Upload de um arquivo","description":"Essa funcionalidade \xe9 a mais importante da aplica\xe7\xe3o, essa funcionalidade \xe9 a que d\xe1 valor ao cliente; \xe9 o diferencial desde projeto","source":"@site/docs/backend/upload-de-um-arquivo.md","sourceDirName":"backend","slug":"/backend/upload-de-um-arquivo","permalink":"/filemanager/docs/backend/upload-de-um-arquivo","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"endpoint","permalink":"/filemanager/docs/backend/endpoint"},"next":{"title":"Frontend - Client Side","permalink":"/filemanager/docs/category/frontend---client-side"}}');var o=n(4848),i=n(8453);const t={sidebar_position:5},r="Upload de um arquivo",d={},c=[{value:"Testes",id:"testes",level:2},{value:"Implementa\xe7\xe3o",id:"implementa\xe7\xe3o",level:2}];function l(e){const s={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(s.header,{children:(0,o.jsx)(s.h1,{id:"upload-de-um-arquivo",children:"Upload de um arquivo"})}),"\n",(0,o.jsxs)(s.p,{children:["Essa funcionalidade \xe9 a mais importante da aplica\xe7\xe3o, essa funcionalidade \xe9 a que d\xe1 valor ao cliente; \xe9 o diferencial desde projeto\ne o seu pr\xf3posito. Testar primeiro e depois implementar essa funcionalidade ajudou a entender e facilitou o aprendizado sobre o conceito de ",(0,o.jsx)(s.em,{children:"resumable upload"}),"."]}),"\n",(0,o.jsx)(s.p,{children:"Ap\xf3s ter definido a historia de usu\xe1rios e os cen\xe1rios de testes que far\xe3o dessa funcionalidade, uma funcionalidade bem sucedida.\nPensar nos comportamentos do projeto, ajudou n\xe3o s\xf3 a garantir a qualidade, mas aprender a implementar essa funcionalidade. Mesmo\nque testar, para s\xf3 ent\xe3o implementar, seja uma linha de racicionio fora da curva."}),"\n",(0,o.jsx)(s.h2,{id:"testes",children:"Testes"}),"\n",(0,o.jsxs)(s.p,{children:["o conceito de ",(0,o.jsx)(s.em,{children:"resumable upload"}),", consiste em garantir que o upload do arquivo n\xe3o vai ser pedido, caso haja a queda de internet do\nlado do cliente ou do lado do servidor. O que se sabe sobre esse conceito \xe9 que assim que o upload inicia \xe9 iniciado uma sess\xe3o:"]}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/services/UploadFile.service.spec.ts"',children:'it("when starts an upload session then metadata must be return", async () => {\n  const sessionId = "session-upload-mock-10128376";\n  const metadata = {\n    filename: "1837373-video.mp4",\n    mimetype: "video/mp4",\n    filesize: 1000000,\n    totalChunks: 3,\n  } as MetadataTypesMock;\n\n  const session = await service.startUpload(sessionId, metadata);\n\n  expect(dbMock.insertSession).toHaveBeenCalledWith(\n    sessionId,\n    expect.any(Object)\n  );\n  expect(session.metadata).toEqual(metadata);\n});\n'})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/services/UploadFile.service.mock.ts"',children:"public async startUpload(sessionId: string, metadata: MetadataTypesMock) {\n        const session = {\n            sessionId,\n            metadata,\n            chunks: [],\n            completed: false,\n            createdAt: new Date(),\n        } as UploadSessionTypesMock;\n\n        await this._db.insertSession(sessionId, session);\n        return session;\n    }\n"})}),"\n",(0,o.jsx)(s.p,{children:"Ap\xf3s verificar se sess\xe3o foi salva no banco de dados, \xe9 retornado para o lado do cliente, os metadados do arquivo que est\xe1 sendo\nfeito o upload."}),"\n",(0,o.jsxs)(s.p,{children:['Com os metadados salvos com sucesso, se inicia o upload de cada parte do arquivo. O arquivo no lado do cliente ser\xe1 "quebrado" em\ndiversas partes e cada "pedacinho" do arquivo deve ser armazenado. Al\xe9m de que \xe9 necessario, verificar se cada parte est\xe1 sendo\nsalva com sucesso; o que garante isso, \xe9 um array booleano, todo "pedacinho" salvo com sucesso, ser\xe1 salvo como ',(0,o.jsx)(s.code,{children:"true"})," no array de\nbooleanos, pelo contr\xe1rio ser\xe1 ",(0,o.jsx)(s.code,{children:"false"}),"."]}),"\n",(0,o.jsx)(s.p,{children:"Em outras palavras, o proximo teste verifica isso. Quando a primeira parte \xe9 salva, mas a segunda n\xe3o; e o lado do cliente envia\na terceira parte, o lado do servidor retorna para a segunda parte. Pois, quando o arquivo for montado, n\xe3o esteja corrompido."}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/services/UploadFile.service.spec.ts"',children:'it("when internet connection is down then try it again", async () => {\n  const sessionId = "session-upload-mock-9384673";\n\n  const session = {\n    sessionId,\n    metadata: {\n      filename: "1837373-text-test.txt",\n      mimetype: "text/plain",\n      filesize: 1000000,\n      totalChunks: 3,\n    },\n    chunks: [],\n    completed: false,\n  } as UploadSessionTypesMock;\n\n  dbMock.findSession.mockResolvedValue(session);\n\n  await service.uploadChunk(sessionId, 0, Buffer.from("part 1"));\n\n  expect(storageMock.saveChunk).toHaveBeenCalledWith(\n    sessionId,\n    0,\n    expect.any(Buffer)\n  );\n  expect(dbMock.updateSession).toHaveBeenCalled();\n\n  await service.uploadChunk(sessionId, 1, Buffer.from("part 2"));\n  expect(storageMock.saveChunk).toHaveBeenCalledWith(\n    sessionId,\n    1,\n    expect.any(Buffer)\n  );\n});\n'})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/services/UploadFile.service.mock.ts"',children:"    public async uploadChunk(sessionId: string, chunkIndex: number, chunk: Buffer) {\n        const session = await this._db.findSession(sessionId);\n\n        if (!session) throw new Error('Upload session not found');\n\n        await this._storage.saveChunk(sessionId, chunkIndex, chunk);\n        session.chunks[chunkIndex] = true;\n        await this._db.updateSession(sessionId, session);\n    }\n"})}),"\n",(0,o.jsxs)(s.p,{children:["Por isso, vamos a ultima parte do processo do ",(0,o.jsx)(s.em,{children:"resumable upload"}),', quando todos os "pedacinhos" do arquivo for enviada com sucesso;\no array booleano vai ficar preenchido de ',(0,o.jsx)(s.code,{children:"true"}),". Ent\xe3o, \xe9 hora de juntar todas as partes."]}),"\n",(0,o.jsx)(s.p,{children:"Este teste junta todas as partes e finaliza o teste com sucesso:"}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/services/UploadFile.service.spec.ts"',children:'it("when assemble all chunks then complete upload", async () => {\n  const sessionId = "session-upload-mock-263532";\n\n  const session = {\n    sessionId,\n    metadata: {\n      originalFilename: "succeed-test.txt",\n      filename: "1837373-succeed-test.txt",\n      mimetype: "text/plain",\n      filesize: 33000,\n    },\n    chunks: [true, true],\n    completed: false,\n  };\n\n  dbMock.findSession.mockResolvedValue(session);\n  storageMock.assembleChunks.mockResolvedValue(Buffer.from("part1part2"));\n\n  const result = await service.completeUpload(sessionId);\n\n  expect(storageMock.save).toHaveBeenCalledWith(result.id, expect.any(Buffer));\n  expect(dbMock.insert).toHaveBeenCalledWith(\n    expect.objectContaining({\n      filename: "1837373-succeed-test.txt",\n    })\n  );\n  expect(dbMock.deleteSession).toHaveBeenCalledWith(sessionId);\n});\n'})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/services/UploadFile.service.mock.ts"',children:" public async completeUpload(sessionId: string): Promise<FileMetadataTypesMock> {\n        const session = await this._db.findSession(sessionId);\n        if (!session) throw new Error('Upload session not found');\n\n        const { totalChunks } = session.metadata;\n        const receivedChunks = session.chunks ?? [];\n\n        const missing: number[] = [];\n        for (let i = 0; i < totalChunks; i++) {\n            if (!receivedChunks[i]) missing.push(i);\n        }\n\n        if (missing.length > 0) {\n        throw new Error(`Upload incompleto: chunks faltando [${missing.join(', ')}]`);\n        }\n\n        const allChunks = await this._storage.assembleChunks(sessionId);\n        const id = crypto.randomUUID();\n        const createdAt = new Date();\n        const updatedAt = new Date();\n        const downloadUrl = `/download/${id}`;\n\n        await this._storage.save(id, allChunks);\n        const fileData: FileMetadataTypesMock = {\n            ...session.metadata,\n            id,\n            createdAt,\n            updatedAt,\n            downloadUrl,\n        };\n\n        await this._db.insert(fileData);\n        await this._db.deleteSession(sessionId);\n\n        return fileData;\n    }\n"})}),"\n",(0,o.jsx)(s.p,{children:"N\xe3o ser\xe1 discutido nessa p\xe1gina os ultimos dois testes que visam em verificar o comportamento do upload para arquivos grandes, pois\npor estar sendo usado mocks; os mocks n\xe3o lidam muito bem com arquivos grandes, podem falhar mesmo se o teste estar escrito corretamente."}),"\n",(0,o.jsxs)(s.p,{children:["Para realizar testes com arquivos grandes, o ideal \xe9 realizar um teste de carga, isso pode ser feito pelo frontend, ",(0,o.jsx)(s.code,{children:"curl"}),",\nPostman, Insominia ou ",(0,o.jsx)(s.code,{children:"supertest"}),"."]}),"\n",(0,o.jsxs)(s.p,{children:["Os testes n\xe3o s\xf3 ajudaram na implementa\xe7\xe3o, mas tamb\xe9m ajudaram a pensar em algumas refatora\xe7\xf5es, como por exemplo: escrever uma\n",(0,o.jsx)(s.code,{children:"interface"})," para o tipo de ",(0,o.jsx)(s.code,{children:"Metadado"})," e ",(0,o.jsx)(s.code,{children:"Sess\xe3o"})," do upload."]}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/file/types/FileMetadata.types.mock.ts"',children:"export interface FileMetadataTypesMock {\n  id: string;\n  filename: string;\n  mimetype: string;\n  filesize: number;\n  createdAt: Date;\n  updatedAt: Date;\n}\n"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="test/core/domain/upload_session/types/UploadSessionMetadata.types.mock.ts"',children:"export interface MetadataTypesMock {\n  filename: string;\n  mimetype: string;\n  totalChunks: number;\n}\n\nexport interface UploadSessionTypesMock {\n  sessionId: string;\n  metadata: MetadataTypesMock;\n  chunks: boolean[];\n  completed: boolean;\n}\n"})}),"\n",(0,o.jsx)(s.h2,{id:"implementa\xe7\xe3o",children:"Implementa\xe7\xe3o"}),"\n",(0,o.jsx)(s.p,{children:"A cada teste foi implementado a fun\xe7\xe3o real que foi testada, e foi pensado em usar GridFSBucket para poder armazenar arquivos grandes,\nesses arquivos embora estejam tendo suas partes salvas em uma pasta temporaria no backend. O arquivo final fica no MongoDB. GridFS \xe9\nideal para arquivos grandes."}),"\n",(0,o.jsx)(s.p,{children:"Como foi planejado nos testes, primeiro \xe9 salvo a sess\xe3o no banco de dados. Abaixo est\xe1 a implementa\xe7\xe3o da funcionalidade tanto no\nrepositorio, quando na classe de servi\xe7o:"}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/upload_session/repository/UploadSession.repository.ts"',children:"async insertSession(sessionId: string, session: any) {\n    await UploadSessionModel.create({ ...session, sessionId });\n  }\n"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/file/services/File.service.ts"',children:"public async startUpload(sessionId: string, metadata: MetadataTypes) {\n    const session = {\n      sessionId,\n      metadata,\n      chunks: [],\n      completed: false,\n    } as UploadSessionTypes;\n    await this.uploadSessionRepository.insertSession(sessionId, session);\n    return session;\n  }\n"})}),"\n",(0,o.jsx)(s.p,{children:"Depois de planejado o salvamento da sess\xe3o, cada parte do arquivo, ent\xe3o \xe9 armazenada na backend e a sess\xe3o \xe9 atualizada, conforme\nfoi implementada, na classe de servi\xe7o, armazenamento e repositorio:"}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/upload_session/repository/UploadSession.repository.ts"',children:"  async findSession(sessionId: string) {\n    return UploadSessionModel.findOne({ sessionId }).lean();\n  }\n\n"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/infrastructure/gridfs/GridFsStorage.impl.ts"',children:"  async saveChunk(sessionId: string, index: number, chunk: Buffer) {\n    const dir = join(tmpdir(), sessionId);\n    await fs.mkdir(dir, { recursive: true });\n    const chunkPath = join(dir, `${index}`);\n    await fs.writeFile(chunkPath, chunk);\n  }\n"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/file/services/File.service.ts"',children:'  public async uploadChunk(sessionId: string, chunkIndex: number, chunk: Buffer) {\n    const storage =  getGridFSStorage();\n    const session = await this.uploadSessionRepository.findSession(sessionId);\n    if (!session) throw new Error("Upload session not found");\n\n    await storage.saveChunk(sessionId, chunkIndex, chunk);\n    session.chunks[chunkIndex] = true;\n    await this.uploadSessionRepository.updateSession(sessionId, session);\n  }\n'})}),"\n",(0,o.jsxs)(s.p,{children:["Por fim, o upload deve ser concluido, conforme o terceiro teste realizado. A implementa\xe7\xe3o deve concatenar todos os binarios em um\nunico ",(0,o.jsx)(s.code,{children:"Buffer"})," e esse buffer, deve ser amazenado no GridFS, ent\xe3o o repositorio da cole\xe7\xe3o de arquivos salva o novo arquivo e deleta a sess\xe3o que\nestava salva no banco de dados."]}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/upload_session/repository/UploadSession.repository.ts""',children:"async findSession(sessionId: string) {\n    return UploadSessionModel.findOne({ sessionId }).lean();\n  }\n\nasync deleteSession(sessionId: string) {\n    await UploadSessionModel.deleteOne({ sessionId });\n  }\n"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/file/repository/File.repository.ts"',children:"  async insert(fileData: FileMetadataTypes) {\n    await FileModel.create(fileData);\n  }\n"})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/infrastructure/gridfs/GridFsStorage.impl.ts"',children:'  async assembleChunks(sessionId: string): Promise<Buffer> {\n    const dir = join(tmpdir(), sessionId);\n    const files = await fs.readdir(dir);\n    const buffers: Buffer[] = [];\n\n    const sortedFiles = files.map(Number).sort((a, b) => a - b);\n    for (const i of sortedFiles) {\n      const chunk = await fs.readFile(join(dir, `${i}`));\n      buffers.push(chunk);\n    }\n\n    await fs.rm(dir, { recursive: true, force: true });\n    return Buffer.concat(buffers);\n  }\n\n  async save(fileId: string, data: Buffer) {\n    const stream = this.bucket.openUploadStream(fileId);\n    const readable = Readable.from(data);\n    readable.pipe(stream);\n    await new Promise((resolve, reject) => {\n      stream.on("finish", resolve);\n      stream.on("error", reject);\n    });\n  }\n'})}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-ts",metastring:'title="src/core/domain/file/services/File.service.ts"',children:'  public async completeUpload(sessionId: string): Promise<FileMetadataTypes> {\n    const storage =  getGridFSStorage();\n    const session = await this.uploadSessionRepository.findSession(sessionId);\n    if (!session) throw new Error("Upload session not found");\n\n    const allChunks = await storage.assembleChunks(sessionId);\n    const id = randomUUID();\n    const createdAt = new Date();\n    const updatedAt = new Date();\n\n    await storage.save(id, allChunks);\n\n    const fileData: FileMetadataTypes = {\n      id,\n      filename: session.metadata.filename,\n      mimetype: session.metadata.mimetype,\n      filesize: allChunks.length,\n      createdAt,\n      updatedAt,\n    };\n\n    await this.fileRepository.insert(fileData);\n    await this.uploadSessionRepository.deleteSession(sessionId);\n\n    return fileData;\n  }\n'})})]})}function u(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,o.jsx)(s,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>t,x:()=>r});var a=n(6540);const o={},i=a.createContext(o);function t(e){const s=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),a.createElement(i.Provider,{value:s},e.children)}}}]);